{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Geospatial analysis in R\"\nauthor: \"Philippe Marchand\"\noutput: \n  html_document:\n    toc: true\n    toc_depth: 1\n---\n\n# Geospatial analysis in R\n\nThis lesson presents a brief overview of some of the key R packages for geospatial analysis. Specifically, we will learn how to perform the following spatial processing tasks in R:\n\n- [load and plot vector layers](#importing-vector-data) (points, lines and polygons);\n- [subset vector layers](#subsetting-vector-layers) based on associated data or on another layer (overlay);\n- read projections and [transform coordinates](#coordinate-transformations);\n- perform [geometric operations](#geometric-operations-on-vector-layers) (union, intersection and buffering) on polygon layers;\n- [load, subset and plot raster layers](#working-with-raster-data) (grids of pixels);\n- [filter (mask) and aggregate raster pixels](#raster-math);\n- [extract raster values](#the-extract-function) based on a vector layer.\n\nThe R scripting approach to geospatial analysis may initially seem inconvenient or unintuitive, compared to the point-and-click interface of GIS software. However, the additional effort of coding all the steps of an analysis workflow makes it much easier for anyone - including the code's author - to reproduce the same analysis on new or updated data. R scripts can also serve to automate and distribute large processing tasks in a high-performance computing environment (such as SESYNC's SLURM cluster). \n\n\n## Importing vector data\n\nWe start by importing a layer of polygons corresponding to US counties. The data is available from the US Census website (http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_county_500k.zip), but we will load a local copy from the SESYNC server.\n\nIn the code below, we load two R packages: **sp** and **rgdal**. The former defines spatial data classes in R and is thus a prerequisite for most other spatial analyses packages; the latter is an interface to the open source Geospatial Data Abstraction Library (GDAL) that enables R to import spatial data stored in different file formats. Note that in order to use rgdal in a Linux/UNIX environment, you need to first [install GDAL](http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries).\n\nTo import a .shp shapefile, we call the `readOGR` function from rgdal. This function takes at minimum two arguments, corresponding to the file location (`dsn`) and layer name (`layer`); in general, the layer name should match the filename without its extension.\n\n```{r load_counties, message=FALSE, warning=FALSE}\nlibrary(sp)\nlibrary(rgdal)\ncb_dir <- \"/nfs/public-data/census-tiger-2013/cb_2014_us_county_500k\"\ncounties <- readOGR(dsn = file.path(cb_dir, \"cb_2014_us_county_500k.shp\"),\n                    layer = \"cb_2014_us_county_500k\", stringsAsFactors = FALSE)\n```\n\nBecause each polygon in the shapefile has attached data, the resulting object is a *SpatialPolygonsDataFrame*. (Note that the `stringsAsFactors` argument we specified works the same as for regular data frames.) By exploring its structure in the RStudio Environment tab, we see that it contains a data frame (`counties@data`) and a list of polygons (`counties@polygons`). Although we cannot see the full object under Environment, you can type `counties@proj4string` or `counties@bbox` in the R console to see the layer's projection information and its bounding box, respectively. A *SpatialPolygons* object is a polygon layer with the same components, but no attached `@data`. Analogous classes exist for point (*SpatialPoints*, *SpatialPointsDataFrame*) and line (*SpatialLines*, *SpatialLinesDataFrame*) layers.\n\n*Note*: The reason why we use \"@\" rather than \"$\" to access parts of this object has to do with object-oriented programming systems in R and is beyond the scope of this lesson. However, you can always look at the structure of an object, either with the `str()` function or in the RStudio Environment tab, to know which of the two characters applies.\n\nEach of the *Polygons* object in a *SpatialPolygons* or *SpatialPolygonsDataFrame* contains one or more *Polygon* objects, which are simple polygons in the geometric sense; a single *Polygons* object can thus be a complex shape combining many polygons with holes in them. The `@coords` slot of a *Polygon* is a matrix with the (*x*,*y*) coordinates of each vertex, with the first and last vertices being identical to form a \"closed\" shape.\n\n![](bivand_fig2_4.png)\n\n*Source: Bivand et al. (2013), Applied Spatial Data Analysis with R, p.40* \n\nThe diagram above summarizes the hierarchical structure of *SpatialPolygons* (and *SpatialLines*) objects. Although we will only deal with the full spatial objects in this lesson, understanding this structure is useful for more complex operations, e.g. when you need to apply a custom function on each individual polygon.\n\nThe spatial objects defined by the sp package are compatible with the base R `plot` function. We now plot the counties map, setting *x* and *y* limits to only display the continental US.\n```{r plot_counties}\nplot(counties, xlim = c(-125, -65), ylim = c(20, 50))\n```\n\nInstead of importing a shapefile, we can build spatial objects from coordinate matrices in R. Let's create a *SpatialPoints* object with a single point, corresponding to SESYNC's coordinates in decimal degrees.\n```{r create_point}\nsesync <- SpatialPoints(cbind(-76.505206, 38.9767231), \n                        proj4string = CRS(proj4string(counties)))\n```\nWe joined the *x* and *y* values with `cbind` rather than `c` since the input coordinates must be a two-column matrix. We defined the new object's coordinate system to match that of *counties*. Note that the `CRS()` function (for coordinate reference system) is required to assign the proj4string of one object to another object. \n\nWhen two spatial layers share the same coordinate system, they can be superposed on the same plot. The spatial version of `plot` accepts an `add` parameter to add a layer to the last plot. It also accepts standard R graphical parameters such as color (`col`) and point shape (`pch`).\n```{r plot_point}\nplot(counties, xlim = c(-125, -65), ylim = c(20, 50))\nplot(sesync, col = \"green\", pch = 20, add = TRUE)\n```\n\n\n## Subsetting vector layers\n\nA *Spatial...DataFrame* can be subset with expressions in brackets, just like a regular R data frame.\n```{r subset_md}\ncounties_md <- counties[counties$STATEFP == \"24\", ]  # 24 is the FIPS code for Maryland\nplot(counties_md)\n```\n\nThe code above selects specific rows (corresponding to counties in Maryland) along with the polygons corresponding to those rows. In contrast, subsetting by columns would only affect the data frame component.\n\nA spatial *overlay* operation can be seen as a type of subset based on spatial (rather than data) matching. It is implemented with the `over(sp1, sp2)` function in sp. The exact output depends on the type of layers being matched; if *sp1* is a *SpatialPoints* layer and *sp2* is a *SpatialPolygonsDataFrame*, the function finds the polygon(s), if any, containing each point in *sp1* and returns the corresponding rows of *sp2*. \n```{r pt_poly_overlay}\nover(sesync, counties_md)\n```\n\n### Exercise 1\n\nProduce a map of Maryland counties with Frederick County colored in red.\n\n[View solution](#solution-1)\n\n\n## Coordinate transformations\n\nFor the next part of this lesson, we import a new polygon layer corresponding to the 1:250k map of US hydrological units (HUC) downloaded from the United States Geological Survey (http://water.usgs.gov/GIS/dsdl/huc250k_shp.zip).\n```{r load_huc, message=FALSE, warning=FALSE}\nhuc <- readOGR(dsn = \"/nfs/public-data/ci-spring2016/Geodata/huc250k.shp\", \n               layer = \"huc250k\", stringsAsFactors = FALSE)\n```\n\nWhile the counties data uses unprojected (longitude, latitude) coordinates, *huc* has an Albers equal-area projection (indicated as \"+proj=aea\"). \n```{r compare_proj}\nproj4string(counties_md)\nproj4string(huc)\n```\nOther parameters differ between the two projections, such as the \"datum\", which indicates the standard by which the irregular surface of the Earth is approximated by an ellipsoid. \n\nFortunately, the rgdal package provides us with a generic function (`spTransform`) to convert spatial objects between any two coordinate systems expressed in standard proj4string notation. In the code below, we input a projection string (*proj1*) matching a different version of the Albers equal-area projection and transform both our polygons layers to that coordinate system. (We define this particular projection to match yet another data source that we will import later in this lesson.) This allows us to plot both layers on the same map.\n\n```{r plot_over}\nproj1 <- \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"\ncounties_md <- spTransform(counties_md, proj1)\nhuc <- spTransform(huc, proj1)\nplot(counties_md)\nplot(huc, add = TRUE, border = \"blue\")\n```\n\n\n## Geometric operations on vector layers\n\nThe **rgeos** package, a R interface to the open source geometry engine [GEOS](http://trac.osgeo.org/geos/), provides various functions to modify and transform the geometric objects in one or more vector layers.\n\nThe last map we produced in the previous section (MD counties and hydrological units) is rather hard to read. Let's consider the following improvements:\n\n- to reduce the number of lines, remove the county boundaries within the state;\n- crop the HUC layer to only show the parts of hydrological units contained within the state boundaries.\n\nThe first step is a spatial **union** operation: we want the resulting object to combine the area covered by all the *Polygons* in `counties_md`. To perform a union of all sub-geometries in a single spatial object, we use the rgeos `gUnaryUnion` function. (This differs from the `gUnion` function which returns the union of two spatial objects.) \n```{r gUnion, message=FALSE, warning=FALSE}\nlibrary(rgeos)\nstate_md <- gUnaryUnion(counties_md)\nplot(state_md)\n```\n\nThe second step is a spatial **intersection**, since we want the resulting object to be limited to the areas covered by both *huc* and *state_md*. The `byid = TRUE` argument indicates that the intersection should be performed separately for each polygon within *huc*; this way, the individual hydrological units are preserved but any part of them (or any whole polygon) lying outside the *state_md* polygon is cut from the output. In the `id` argument, we specify meaningful labels for each resulting polygon, by pasting a unique number to the name of each hydrological unit from the original *huc* data. (Note that the result of `gIntersection` is a *SpatialPolygons* object with no attached data.)\n```{r gIntersect}\nhuc_md <- gIntersection(huc, state_md, byid = TRUE, \n                        id = paste(1:length(huc), huc$HUC_NAME))\nplot(huc_md, border = \"blue\")\ntext(coordinates(huc_md), labels = names(huc_md), cex = 0.6, srt = 30)\n```\n\nThe rgeos package also includes functions to create a buffer of specific width around a geometry (`gBuffer`), to calculate the shortest distance between geometries (`gDistance`) and the area of polygons (`gArea`). Keep in mind however that all these functions use planar geometry equations and thus become less precise over larger distances, as the effect of the Earth's curvature become non-negligible. To calculate geodesic distances that account for that curvature, check the **geosphere** package.\n\n### Exercise 2\n\nCreate a 5km buffer around the *state_md* borders and plot it as a dotted line (`plot(..., lty = \"dotted\")`) on the same map. *Hint*: Check the layer's units with `proj4string()` and express any distance in those units.\n\n[View solution](#solution-2)\n\n\n## Working with raster data\n\nWhile vector spatial layers are composed of geometrical objects defined by their vertices, raster layers are defined as grids of pixels with attached values. A raster can be seen as a data matrix with associated spatial properties (e.g. extent, resolution and projection) that allow its values to be mapped onto geographical space.\n\nWe start by loading the **raster** package in R and importing a raster file with the eponymous `raster` function. This file is a portion of the [National Land Cover Database](http://www.mrlc.gov/nlcd2011.php), which we already cropped and reduced to a lower resolution in order to speed up processing time for this tutorial.\n\n```{r load_raster, fig.keep=\"last\"}\nlibrary(raster)\nnlcd <- raster(\"/nfs/public-data/ci-spring2016/Geodata/nlcd_agg.grd\")\nnlcd # show raster properties\nplot(nlcd)\n```\n\nAs shown in the code above, we can access the properties of a raster by simply typing its name in the console. By default, the whole raster is *not* loaded into working memory, as you can confirm by checking the R object size with `object.size(nlcd)`. This means that unlike most analyses in R, you can actually process raster datasets larger than the RAM available on your computer; the raster package automatically loads pieces of the data and computes on each of them in sequence.\n\nThe `crop` function crops a raster layer to a given spatial *extent* (range of *x* and *y* values). The extent can be extracted from another spatial object with `extent`. Here, we crop the *nlcd* raster to the extent of the *huc_md* polygons, then display both layers on the same map. \n```{r crop_raster, fig.keep=\"last\"}\nnlcd <- crop(nlcd, extent(huc_md))\nplot(nlcd)\nplot(huc_md, add = TRUE)\n```\n\nNote that the transformed raster is now loaded in R memory, as indicated by the size of `nlcd`. We could have also saved the output to disk by specifying an optional `filename` argument to `crop`; the same is true for othe raster transformation functions.\n\nA raster is fundamentally a data matrix, and individual pixel values can be extracted by regular matrix subscripting. For example, this returns the value of the bottom-left corner pixel:\n```{r get_raster_values}\nnlcd[1,1]\n```\n\nThe meaning of this number is not immediately clear. For this particular dataset, the mapping of values to land cover classes is described in the data attributes:\n```{r raster_attr}\nstr(nlcd@data@attributes)\n```\n\nWe save the `Land.Cover.Class` column as a new vector in order to easily check the land cover type corresponding to any numeric value. Note however that we need to add 1 to the raster value, since these go from 0 to 255 whereas the indexing of a vector starts at 1.\n```{r lc_types}\nlc_types <- nlcd@data@attributes[[1]]$Land.Cover.Class\nlc_types[42]\n```\n\n\n## Raster math\n\nBasic mathematical operations in R are directly applicable to rasters. For example, `log(r1)` returns a new raster where each pixel's value is the log of the corresponding pixel in `r1`; `r1 + r2` creates a raster where each pixel is the sum of the values from `r1` and `r2` (provided their dimensions match), etc.\n\nThe same applies for logical operations: `r1 > 5` returns a logical raster with pixel values `TRUE` or `FALSE` depending on the value of the corresponding pixels in `r1`. Logical rasters are particularly useful with the `mask` function. The following code creates a new raster from `nlcd`, removing all pixels where the masking condition (`nlcd == 81`) is false (`maskvalue = FALSE`).\n```{r mask, fig.keep=\"last\"}\npasture <- mask(nlcd, nlcd == 81, maskvalue = FALSE)\nplot(pasture)\n```\n\nThe `cellStats` function calculates a summary statistic (e.g. `cellStats(r1, \"mean\")`) across the entire raster layer. Alternatively, we can `aggregate` values locally in a raster, for blocks of a given size, which produces a raster with a lower resolution.\n```{r agg_raster, fig.keep=\"last\"}\nnlcd_agg <- aggregate(nlcd, fact = 5, fun = modal)\nnlcd_agg@legend <- nlcd@legend\nplot(nlcd_agg)\n```\n\nHere, `fact = 5` means that we are aggregating blocks 5 x 5 pixels and `fun = modal` indicates that the aggregate value is the mode of the original pixels (averaging would not work since land cover is a categorical variable).\n\n### Exercise 3\n\nWhich proportion of `nlcd` pixels are covered by deciduous forest (value = 41)? *Hint*: Use `cellStats`.\n\n[View solution](#solution-3)\n\n\n## The extract function\n\nFinally, we look at the `extract` function, which allows subsetting and aggregation of raster values based on the vector spatial objects. When extracting by point locations (i.e. a *SpatialPoints* object), the result is a vector of values corresponding to each point.\n```{r extract_pt}\nsesync <- spTransform(sesync, proj1)\nsesync_lc <- extract(nlcd, sesync)\nlc_types[sesync_lc + 1]\n```\n\nWhen extracting with a polygon, the output is a vector of all raster values for pixels falling within that polygon.\n```{r extract_poly1}\nhuc_nlcd <- extract(nlcd, huc_md[1])\ntable(huc_nlcd)\n```\n\nTo get a summary of raster values for each polygon in a *SpatialPolygons*, we can add an aggregation function to `extract` via the `fun` argument. The following code calculates the most common land cover type (`fun = modal`) for each polygon in *huc_md*.\n```{r extract_poly_agg}\nmodal_lc <- extract(nlcd_agg, huc_md, fun = modal)\nmodal_lc <- lc_types[modal_lc + 1]\ndata.frame(names(huc_md), modal_lc)\n```\n\nFor a more detailed introduction to the raster package, you can consult [this vignette in CRAN](http://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf).\n\n\n## Additional references\n\n(Book) R.S. Bivand, E.J. Pebesma and V. Gómez-Rubio (2013) Applied Spatial Data Analysis with R. UseR! Series, Springer.\n\nR. Lovelace, J. Cheshire et al., Introduction to visualising spatial data in R. <https://cran.r-project.org/doc/contrib/intro-spatial-rl.pdf>\n\nF. Rodriguez-Sanchez. Spatial data in R: Using R as a GIS. \n<http://pakillo.github.io/R-GIS-tutorial/>\n\nCRAN Task View: Analysis of Spatial Data.\n<https://cran.r-project.org/web/views/Spatial.html>\n\n\n## Exercise solutions\n\n\n### Solution 1\n\nProduce a map of Maryland counties with Frederick County colored in red.\n\n```{r sol1, eval=FALSE}\nplot(counties_md)\nfrederick <- counties_md[counties_md$NAME == \"Frederick\", ]\nplot(frederick, add = TRUE, col = \"red\")\n```\n\n[Return](#exercise-1)\n\n\n### Solution 2\n\nCreate a 5km buffer around the *state_md* borders and plot it as a dotted line (`plot(..., lty = \"dotted\")`) on the same map.\n\n```{r sol2, eval=FALSE}\nbuffer <- gBuffer(state_md, width = 5000)\nplot(state_md)\nplot(buffer, lty = \"dotted\", add = TRUE)\n```\n\n[Return](#exercise-2)\n\n\n### Solution 3\n\nWhich proportion of `nlcd` pixels are covered by deciduous forest (value = 41)?\n\n```{r sol3, eval=FALSE}\ncellStats(nlcd == 41, \"mean\")\n```\n\n[Return](#exercise-3)\n",
    "created" : 1465776712314.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3297357854",
    "id" : "D2767F81",
    "lastKnownWriteTime" : 1465778218,
    "last_content_update" : 1465778218987,
    "path" : "~/sesync-ci/geospatial-packages-in-R-lesson/index.Rmd",
    "project_path" : "index.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}